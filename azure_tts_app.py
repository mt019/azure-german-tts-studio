import os
import subprocess
import re
from datetime import datetime

import streamlit as st
import azure.cognitiveservices.speech as speechsdk
import streamlit.components.v1 as components
import base64


YOUTUBE_DESCRIPTION_TEMPLATES = {
    # ä¸€èˆ¬å¾·æ–‡è½åŠ› / é–±è®€ / å£èªè·Ÿè®€
    "general_listening": """#Deutschlernen #GermanListening #TELC #Deutschverstehen
ğŸ“Œ Deutsche HÃ¶rÃ¼bung â€“ Vorlesen eines Ãœbungstextes zur PrÃ¼fungsvorbereitung

In diesem Video wird ein deutscher Ãœbungstext langsam, deutlich und mit natÃ¼rlicher Betonung vorgelesen. Ideal fÃ¼r:
âœ“ Vorbereitung auf TestDaF / DSH / Goethe / TELC
âœ“ Training des HÃ¶rverstehens
âœ“ Schattenlesen (Shadowing) und Nachsprechen
âœ“ Wortschatzaufbau und Festigung grammatischer Strukturen
âœ“ GewÃ¶hnung an akademische HÃ¶rtexte

ğŸ—£ Sprecher: Standarddeutscher Sprecher mit neutraler, klarer Aussprache  
ğŸ§ Inhalt: Vorlesen eines sachlichen deutschen Textes in prÃ¼fungsnahem Stil

Tipps zum Lernen:
1. Zuerst ohne Untertitel hÃ¶ren
2. Danach mit deutschen Untertiteln (automatisch erzeugt) erneut anhÃ¶ren
3. Den Text laut nachsprechen (Shadowing)
4. Mehrmals wiederholen â€“ Sprache lernt man durch Wiederholung

ğŸ’¡ Lerntipp:  
Dieses Video lÃ¤sst sich sehr gut zusammen mit dem Browserâ€‘Addâ€‘on **Language Reactor** verwenden (https://www.languagereactor.com/).  
Damit kannst du Untertitel bequemer steuern, Vokabeln speichern und schwierige Stellen mehrfach im Kontext wiederholen.

Wenn du weitere deutsche HÃ¶rÃ¼bungen mÃ¶chtest, freue ich mich Ã¼ber einen Kommentar oder ein Abo!

#Deutschlernen #GermanListening #TestDaF #DSH #TELC #Goethe #GermanAudio #DeutschfÃ¼rAuslÃ¤nder #GermanPractice #GermanReading #Deutschverstehen""",
    # å¾·ç¦ / é«˜éšè€ƒè©¦ï¼šè½åŠ›é‡é»
    "testdaf_listening": """#TestDaF #Deutschlernen #HÃ¶rverstehen #GermanListening
ğŸ“Œ TestDaF / HochschulprÃ¼fung â€“ HÃ¶rverstehen-Training mit authentischem Ãœbungstext

In diesem Video hÃ¶rst du einen deutschen Ãœbungstext im prÃ¼fungsnahen Stil. Ideal fÃ¼r:
âœ“ Vorbereitung auf TestDaF, DSH, telc Hochschule
âœ“ Training des globalen und selektiven HÃ¶rverstehens
âœ“ GewÃ¶hnung an akademische HÃ¶rtexte und typische PrÃ¼fungssituationen

ğŸ—£ Sprecher: neutrale, deutliche Aussprache in Standarddeutsch  
ğŸ§ Fokus: HÃ¶rverstehen, Notizen machen, Struktur erkennen

Lerntipps:
1. Zuerst einmal ohne Untertitel hÃ¶ren und nur grob mitschreiben
2. Beim zweiten HÃ¶ren gezielt auf Details achten (Zahlen, Argumente, Beispiele)
3. Schwierige Stellen mehrfach wiederholen, bis die Struktur klar ist
4. Zum Schluss laut mitsprechen (Shadowing), um Aussprache und Rhythmus zu Ã¼ben

ğŸ’¡ Bonus:  
Zusammen mit **Language Reactor** im Browser kannst du Untertitel, Pausen und Wiederholungen noch besser steuern.

Wenn dir dieses HÃ¶rtraining hilft, lass gerne einen Kommentar oder ein Abo da.

#TestDaF #DSH #telcC1 #GermanExam #HÃ¶rverstehen #DeutschfÃ¼rStudium""",
    # å¾·ç¦ / å£èªé¡Œå‹
    "testdaf_speaking": """#TestDaF #Deutschlernen #Sprechen #GermanSpeaking
ğŸ“Œ TestDaF MÃ¼ndliche PrÃ¼fung â€“ Sprechanlass / Antwortbausteine zum Mitsprechen

Dieses Video ist fÃ¼r die Vorbereitung auf die mÃ¼ndliche PrÃ¼fung gedacht. Ideal fÃ¼r:
âœ“ TestDaF-Aufgaben zur Beschreibung, MeinungsÃ¤uÃŸerung und Diskussion
âœ“ Strukturierte Antwortbausteine (Einleitung â€“ Argumente â€“ Schluss)
âœ“ Lautes Mitsprechen (Shadowing) fÃ¼r mehr Sicherheit im Ausdruck

ğŸ—£ Fokus: flÃ¼ssiges, zusammenhÃ¤ngendes Sprechen in PrÃ¼fungssituationen  
ğŸ¯ Ziel: typische Redemittel automatisieren, damit im Ernstfall mehr KapazitÃ¤t fÃ¼rs Denken bleibt

ğŸ’¡ Lerntipps:
1. HÃ¶re den Text zuerst komplett durch und achte auf Aufbau und Redemittel
2. Spule zurÃ¼ck und sprich einzelne SÃ¤tze oder Abschnitte laut nach
3. Pausiere das Video und versuche, Ã¤hnliche Antworten mit eigenen Inhalten zu formulieren
4. Wiederhole das Ganze mehrmals an verschiedenen Tagen, damit die Strukturen im Kopf bleiben

 
Dieses Video lÃ¤sst sich sehr gut zusammen mit dem Browserâ€‘Addâ€‘on **Language Reactor** verwenden (https://www.languagereactor.com/).  
Damit kannst du Untertitel bequemer steuern, Vokabeln speichern und schwierige Stellen mehrfach im Kontext wiederholen.

Wenn du dir mehr Vorlagen fÃ¼r mÃ¼ndliche PrÃ¼fungen wÃ¼nschst, schreib es gern in die Kommentare.

#TestDaF #MÃ¼ndlichePrÃ¼fung #DeutschSprechen #Redemittel #GermanOralExam""",
    # å¾·ç¦ / æ›¸å¯«é¡Œå‹
    "testdaf_writing": """#TestDaF #Deutschlernen #Schreiben #GermanWriting
ğŸ“Œ TestDaF Schriftlicher Ausdruck â€“ Mustertext / Formulierungshilfen

In diesem Video wird ein Mustertext fÃ¼r die schriftliche PrÃ¼fung vorgelesen. Ideal fÃ¼r:
âœ“ Vorbereitung auf den schriftlichen Ausdruck im TestDaF
âœ“ EinÃ¼ben von typischen Einleitungen, Ãœberleitungen und Schlussformulierungen
âœ“ Wiederkehrende Formulierungen fÃ¼r Argumentation, Beschreibung und Stellungnahme

ğŸ—£ Sprecher: ruhige, deutliche Aussprache in Standarddeutsch  
ğŸ“„ Inhalt: prÃ¼fungsnaher Beispieltext, der sich gut als Vorlage oder Inspiration eignet

ğŸ’¡ Lerntipps:
1. HÃ¶re den Text einmal komplett, nur um Struktur und Aufbau zu verstehen
2. Lies (oder hÃ¶re) Abschnitt fÃ¼r Abschnitt und markiere dir nÃ¼tzliche Redemittel
3. Versuche dann, mit denselben Bausteinen eigene Texte zu einem anderen Thema zu formulieren
4. Nutze den Text zum laut Vorlesen, um Schriftbild und Aussprache gleichzeitig zu trainieren

ğŸ’¡ Bonus:  
Dieses Video lÃ¤sst sich sehr gut zusammen mit dem Browserâ€‘Addâ€‘on **Language Reactor** verwenden (https://www.languagereactor.com/).  
Damit kannst du Untertitel bequemer steuern, Vokabeln speichern und schwierige Stellen mehrfach im Kontext wiederholen.

Wenn du mehr Beispieltexte fÃ¼r schriftliche PrÃ¼fungen brauchst, lass gern einen Kommentar oder ein Abo da.

#TestDaF #SchriftlicherAusdruck #DeutschSchreiben #GermanWriting #DeutschPrÃ¼fung"""
}

DEFAULT_YT_TEMPLATE_KEY = "general_listening"

def get_speech_config() -> speechsdk.SpeechConfig:
    # å„ªå…ˆå¾ Streamlit secrets è®€å–
    key = st.secrets.get("SPEECH_KEY")
    region = st.secrets.get("SPEECH_REGION")

    if not key or not region:
        st.error(
            "æ‰¾ä¸åˆ° Azure TTS é‡‘é‘°è¨­å®šã€‚\n"
            "è«‹åœ¨ .streamlit/secrets.toml ä¸­è¨­å®š SPEECH_KEY å’Œ SPEECH_REGIONã€‚"
        )
        st.stop()

    speech_config = speechsdk.SpeechConfig(
        subscription=key,
        region=region,
    )
    # é è¨­å¾·èªå¥³è²ï¼Œå¯åœ¨ UI ä¸­è¦†è“‹
    speech_config.speech_synthesis_voice_name = "de-DE-KatjaNeural"
    # ç›´æ¥è¼¸å‡º MP3
    speech_config.set_speech_synthesis_output_format(
        speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3
    )
    return speech_config


def main():
    st.set_page_config(page_title="Azure TTS Demo", layout="wide")

    st.title("Azure Text-to-Speech èªéŸ³åˆæˆ Demo")

    # ====== å´é‚Šæ¬„ï¼šèªªæ˜èˆ‡æ‰€æœ‰é…ç½® ======
    selected_description_template_key = DEFAULT_YT_TEMPLATE_KEY
    current_description_template = YOUTUBE_DESCRIPTION_TEMPLATES[DEFAULT_YT_TEMPLATE_KEY]
    with st.sidebar:
        st.header("è¨­å®šèˆ‡èªªæ˜")
        with st.expander("ä½¿ç”¨èªªæ˜ï¼ˆé»æˆ‘å±•é–‹ / æ”¶åˆï¼‰", expanded=False):
            st.markdown(
                """
                ä½¿ç”¨ Azure Speech Service å°‡æ–‡å­—è½‰æˆèªéŸ³æª”æ¡ˆã€‚

                åœ¨åŸ·è¡Œæœ¬ç¨‹å¼å‰ï¼Œè«‹å…ˆï¼š
                - å®‰è£å¥—ä»¶ï¼š`pip install azure-cognitiveservices-speech streamlit`
                - è¨­å®š Streamlit secretsï¼ˆæ¨è–¦ï¼‰æˆ–ç’°å¢ƒè®Šæ•¸ï¼š
                  - `SPEECH_KEY`ï¼šAzure Speech è³‡æºé‡‘é‘°ï¼ˆTTS ç”¨ï¼‰
                  - `SPEECH_REGION`ï¼šAzure Speech è³‡æº regionï¼ˆä¾‹å¦‚ï¼š`eastasia`ï¼‰
                """
            )
        # st.markdown("---")
        st.subheader("YouTube èªªæ˜æ¬„æ¨¡æ¿")
        yt_template_labels = {
            "ä¸€èˆ¬ï¼šè½åŠ› / é–±è®€ / è·Ÿè®€": "general_listening",
            "å¾·ç¦ HÃ¶rverstehenï¼ˆè½åŠ›é¡Œï¼‰": "testdaf_listening",
            "å¾·ç¦ MÃ¼ndliche PrÃ¼fungï¼ˆå£èªé¡Œï¼‰": "testdaf_speaking",
            "å¾·ç¦ Schriftlicher Ausdruckï¼ˆå¯«ä½œé¡Œï¼‰": "testdaf_writing",
        }
        selected_yt_label = st.selectbox(
            "é¸æ“‡èªªæ˜æ¬„ç”¨é€”ï¼ˆæœƒå½±éŸ¿æ¨¡æ¿å…§å®¹ï¼‰ï¼š",
            list(yt_template_labels.keys()),
            index=0,
        )
        selected_description_template_key = yt_template_labels[selected_yt_label]
        current_description_template = YOUTUBE_DESCRIPTION_TEMPLATES.get(
            selected_description_template_key,
            YOUTUBE_DESCRIPTION_TEMPLATES[DEFAULT_YT_TEMPLATE_KEY],
        )

        with st.expander("æŸ¥çœ‹ç›®å‰é¸æ“‡çš„èªªæ˜æ¬„æ¨¡æ¿ï¼ˆå¯è¤‡è£½èª¿æ•´ï¼‰", expanded=False):
            st.text_area(
                "ç›®å‰é¸æ“‡çš„ YouTube èªªæ˜æ¬„æ¨¡æ¿ï¼ˆå¯è¤‡è£½è‡ªè¡Œèª¿æ•´ï¼‰ï¼š",
                value=current_description_template,
                height=260,
            )

    st.subheader("æ–‡æœ¬è¼¸å…¥")
    raw_markdown = st.text_area(
        "è«‹è²¼å…¥ Markdown æ–‡æœ¬ï¼ˆæœƒè‡ªå‹•å»é™¤æ¨™è¨˜å¾Œå†é€å»æœ—è®€ï¼‰ï¼š",
        height=260,
    )

    def clean_markdown(text: str) -> str:
        """ç°¡å–®æ¸…æ‰å¸¸è¦‹ Markdown æ¨™è¨˜ï¼Œä¿ç•™ç´”æ–‡å­—ï¼Œä¸¦ç›¡é‡ä¿ç•™åŸå§‹æ›è¡Œã€‚
        ç‰¹åˆ¥è™•ç†ï¼š
        - ä¿ç•™ç¬¬ä¸€å€‹æ¨™é¡Œçš„å…§å®¹ï¼ˆç•¶æˆæ­£æ–‡é–‹é ­ï¼‰ï¼Œå…¶ä»–æ¨™é¡Œä»åˆªé™¤ã€‚
        - å»æ‰å¸¸è¦‹ç²—é«”æ¨™è¨˜ã€é …ç›®ç¬¦è™Ÿèˆ‡ emoji bulletã€‚
        - åŸæ–‡ä¸­çš„æ›è¡Œæœƒç›¡é‡è¢«ä¿ç•™ç‚ºè¡Œåˆ†éš”ç¬¦ã€‚
        """
        lines = text.splitlines()
        kept = []
        first_heading_kept = False
        for line in lines:
            stripped = line.strip()
            # ç©ºè¡Œï¼šä¿ç•™ç‚ºæ®µè½åˆ†éš”ï¼ˆä¹‹å¾Œæœƒè®Šæˆä¸€å€‹ç©ºè¡Œï¼‰
            if not stripped:
                kept.append("")
                continue
            # è©•åˆ†æç¤ºé€™é¡è¡Œç›´æ¥ä¸Ÿæ‰
            if stripped.startswith("âœ…"):
                continue
            # æ¨™é¡Œè™•ç†
            if stripped.startswith("#"):
                # åªä¿ç•™ç¬¬ä¸€å€‹æ¨™é¡Œçš„æ–‡å­—å…§å®¹ï¼Œå…¶é¤˜æ¨™é¡Œç›´æ¥ç•¥é
                if not first_heading_kept:
                    heading_text = stripped.lstrip("#").strip()
                    if heading_text:
                        # è‹¥æ¨™é¡Œæœ«å°¾æ²’æœ‰å¥è™Ÿç­‰ï¼Œè£œä¸Šä¸€å€‹å¥è™Ÿï¼Œæ–¹ä¾¿ä¹‹å¾Œåˆ‡å¥
                        if not heading_text.endswith((".", "!", "?", "ã€‚", "ï¼", "ï¼Ÿ")):
                            heading_text += "."
                        kept.append(heading_text)
                    first_heading_kept = True
                continue
            # åˆ†éš”ç·š / ç¨‹å¼å€å¡Šæ¨™è¨˜
            if stripped.startswith("---") or stripped.startswith("***"):
                continue
            if stripped.startswith("```"):
                continue
            # å»æ‰å¸¸è¦‹é …ç›®ç¬¦è™Ÿèˆ‡ emoji bullet
            stripped = re.sub(r"^[-*+â€¢âœ…â–¶ï¸âœ”ï¸]\s*", "", stripped)
            # å»æ‰ç²—é«” / æ–œé«”æ¨™è¨˜ **text** / *text*
            stripped = re.sub(r"\*\*(.*?)\*\*", r"\1", stripped)
            stripped = re.sub(r"\*(.*?)\*", r"\1", stripped)
            kept.append(stripped)

        # ä»¥æ›è¡Œé‡æ–°æ¥å›æ–‡å­—ï¼Œä»¥ä¿ç•™åŸæœ¬çš„è¡Œçµæ§‹
        joined = "\n".join(kept)
        # å£“ç¸®å¤šé¤˜çš„é€£çºŒç©ºç™½è¡Œï¼ˆæœ€å¤šä¿ç•™å…©å€‹æ›è¡Œï¼‰
        joined = re.sub(r"\n{3,}", "\n\n", joined)
        return joined

    def split_sentences(text: str):
        """æ”¹ç‚ºåªä¾åŸå§‹æ›è¡Œåˆ‡æˆã€Œè¡Œã€ï¼Œä¸å†ç”¨æ¨™é»ç¬¦è™Ÿæ–·å¥ã€‚

        åŸå‰‡ï¼š
        - æ¯ä¸€è¡Œè¦–ç‚ºä¸€å€‹æœ—è®€å–®ä½ã€‚
        - åŸæœ¬ç‚ºç©ºè¡Œçš„ï¼Œä¿ç•™ç‚ºç©ºå­—ä¸²ï¼Œæœ€å¾Œåœ¨é¡¯ç¤ºæ™‚ä»æ˜¯ä¸€å€‹æ›è¡Œã€‚
        - é€™æ¨£å¯é¿å…åƒã€Œz.b.ã€é€™é¡åŒ…å«å¥é»çš„ç¸®å¯«è¢«èª¤åˆ‡æ–·ã€‚
        """
        sentences = []
        for line in text.splitlines():
            # ç›´æ¥ä¿ç•™åŸè¡Œï¼ˆå«ç©ºè¡Œï¼‰ï¼Œåªåšå³å´å»é™¤æ›è¡Œç¬¦è™Ÿ
            sentences.append(line.rstrip("\n"))
        return sentences

    cleaned_text = clean_markdown(raw_markdown) if raw_markdown.strip() else ""

    display_text = ""
    sentences = []
    if cleaned_text:
        sentences = split_sentences(cleaned_text)
        display_text = "\n".join(sentences)

    # ====== é•·æ–‡æœ¬æç¤ºèˆ‡åˆ†æ®µè¨­å®šï¼ˆè‡ªå‹•ä¾å¥æ•¸åˆ‡å‰²ï¼‰ ======
    segmentation_mode = "single"  # "single" æˆ– "auto"
    sentences_per_segment = 5
    word_count = 0

    if cleaned_text:
        word_count = len(cleaned_text.split())

    if sentences:
        st.info(
            f"ç›®å‰æ¸…æ´—å¾Œæ–‡æœ¬ç´„ {word_count} å€‹è©ï¼Œå…± {len(sentences)} å¥ã€‚\n"
            "Azure å–®æ¬¡åˆæˆç´„ 10 åˆ†é˜ä¸Šé™ï¼Œå»ºè­°ä½¿ç”¨è‡ªå‹•åˆ†æ®µä»¥é¿å…è¶…æ™‚æˆ–è¢«å–æ¶ˆã€‚"
        )
        seg_choice = st.radio(
            "é•·æ–‡æœ¬è™•ç†æ–¹å¼ï¼š",
            ["æ•´ç¯‡ä¸€æ¬¡åˆæˆ", "è‡ªå‹•åˆ†æ®µï¼ˆå»ºè­°ï¼‰"],
            index=1,
        )
        if seg_choice == "è‡ªå‹•åˆ†æ®µï¼ˆå»ºè­°ï¼‰":
            segmentation_mode = "auto"
            sentences_per_segment = st.slider(
                "æ¯æ®µå¤§ç´„å¹¾å¥ï¼Ÿï¼ˆè¼ƒå°è¼ƒå®‰å…¨ï¼‰",
                min_value=3,
                max_value=12,
                value=5,
                step=1,
                help="ç¨‹å¼æœƒä¾åºæ¯ N å¥åˆ‡ä¸€æ®µï¼Œæœ€å¾Œä¸€æ®µå¯èƒ½ç•¥çŸ­ã€‚å¥æ•¸æ„ˆå°‘ï¼Œå–®æ®µé•·åº¦æ„ˆå®‰å…¨ã€‚",
            )
            approx_segments = max(1, (len(sentences) + sentences_per_segment - 1) // sentences_per_segment)
            st.caption(
                f"ç›®å‰é ä¼°æœƒåˆ‡æˆç´„ {approx_segments} æ®µï¼ˆå¯¦éš›ä¾å¥æ•¸å¾®èª¿ï¼‰ã€‚"
            )

    combined_for_description = ""
    if display_text:
        st.text_area(
            "é è™•ç†å¾Œï¼ˆæ¯å¥ä¸€è¡Œï¼‰å°‡é€çµ¦ Azure æœ—è®€çš„ç´”æ–‡å­—ï¼ˆå¯æª¢æŸ¥ç”¨ï¼‰ï¼š",
            value=display_text,
            height=220,
        )

    # ====== å´é‚Šæ¬„ï¼šèªéŸ³ / è¼¸å‡ºè¨­å®šèˆ‡ç”¨é‡æç¤º ======
    with st.sidebar:
        st.markdown("---")
        start_clicked = st.button("é–‹å§‹èªéŸ³åˆæˆ")
        st.markdown("---")
        st.subheader("èªéŸ³èˆ‡è¼¸å‡ºè¨­å®š")

        # ä¸€äº›å¸¸ç”¨çš„ Azure Neural voice ç¯„ä¾‹
        voice_options = {
            "å¾·èª å¥³è²ï¼ˆde-DE-KatjaNeuralï¼‰": "de-DE-KatjaNeural",
            "å¾·èª ç”·è²ï¼ˆde-DE-ConradNeuralï¼‰": "de-DE-ConradNeural",
            "è‹±æ–‡ å¥³è²ï¼ˆen-US-JennyNeuralï¼‰": "en-US-JennyNeural",
            "è‹±æ–‡ ç”·è²ï¼ˆen-US-GuyNeuralï¼‰": "en-US-GuyNeural",
            "è‡ªè¨‚ voice åç¨±â€¦": "custom",
        }

        selected_voice_label = st.selectbox(
            "é¸æ“‡ä¸€å€‹ Azure èªéŸ³ï¼ˆvoiceï¼‰ï¼š",
            list(voice_options.keys()),
            index=0,
        )

        custom_voice = ""
        if voice_options[selected_voice_label] == "custom":
            custom_voice = st.text_input(
                "è«‹è¼¸å…¥è‡ªè¨‚çš„ Azure èªéŸ³åç¨±ï¼ˆä¾‹å¦‚ de-DE-ElkeNeuralï¼‰ï¼š",
                value="",
            )

        # æœ€çµ‚è¦æ‹¿ä¾†é€çµ¦ Azure çš„ voice åç¨±
        voice = custom_voice if custom_voice.strip() else voice_options[selected_voice_label]

        mode = st.radio(
            "è¼¸å‡ºé¡å‹ï¼š",
            ["åªç”¢ç”Ÿ MP3 éŸ³æª”", "ç”¢ç”Ÿé»‘åº• MP4 å½±ç‰‡"],
            index=1,  # é è¨­æ”¹ç‚ºã€Œç”¢ç”Ÿé»‘åº• MP4 å½±ç‰‡ã€
        )

        video_lead_seconds = st.slider(
            "å½±ç‰‡é–‹é ­ç©ºç™½ç§’æ•¸ï¼ˆåƒ…å½±éŸ¿ MP4ï¼ŒMP3 ä¸å»¶é²ï¼‰ï¼š",
            min_value=0,
            max_value=10,
            value=5,
            step=1,
        )

        auto_play = st.checkbox(
            "åˆæˆå®Œæˆå¾Œåœ¨ç¶²é ä¸­ç«‹å³æœ—è®€ï¼ˆè‡ªå‹•æ’­æ”¾ï¼Œå¯æš«åœ/ç¹¼çºŒï¼‰",
            value=True,
        )

        base_name = st.text_input(
            "è‡ªè¨‚æª”åå‰ç¶´ï¼ˆé¸å¡«ï¼Œä¸å¡«æ™‚æœƒç”¨ Markdown ç¬¬ä¸€å€‹æ¨™é¡Œ + æ™‚é–“æˆ³ï¼‰ï¼š",
            value="",
        )

        st.markdown("---")
        add_description = False
        if display_text:
            st.caption(f"ç›®å‰å°‡ä½¿ç”¨ï¼šã€Œ{selected_yt_label}ã€é€™å€‹èªªæ˜æ¬„æ¨¡æ¿")
            add_description = st.checkbox(
                "ç”¢ç”ŸåŒ…å«å›ºå®šæ¨¡æ¿çš„ YouTube èªªæ˜æ¬„æ–‡æœ¬",
                value=False,
            )

        st.markdown("---")
        with st.expander("æ–‡å­—ç”¨é‡ï¼ˆé»æˆ‘å±•é–‹ / æ”¶åˆï¼‰", expanded=False):
            char_count = len(cleaned_text)
            monthly_free_chars = 500_000  # F0 / Free Tier æ¯æœˆç´„ 0.5M å­—å…ƒ
            if char_count > 0:
                ratio = char_count / monthly_free_chars * 100
                st.info(
                    f"æœ¬æ¬¡é€çµ¦ Azure çš„æ–‡å­—ç´„ {char_count} å€‹å­—å…ƒã€‚\n"
                    f"è‹¥ä»¥æ¯æœˆå…è²» {monthly_free_chars:,} å­—å…ƒè¨ˆç®—ï¼Œç´„å ç†è«–å…è²»é¡åº¦çš„ {ratio:.2f}%ã€‚"
                )
            else:
                st.write("ç›®å‰é‚„æ²’æœ‰å¯é€çµ¦ Azure çš„æ–‡å­—ã€‚")

    # ç”¢ç”Ÿ YouTube èªªæ˜æ¬„æ–‡æœ¬ï¼ˆé¡¯ç¤ºåœ¨ä¸»å€ï¼‰
    if display_text and 'add_description' in locals() and add_description:
        template_body = YOUTUBE_DESCRIPTION_TEMPLATES.get(
            selected_description_template_key,
            YOUTUBE_DESCRIPTION_TEMPLATES[DEFAULT_YT_TEMPLATE_KEY],
        )
        combined_for_description = f"{display_text}\n\n\n{template_body}"
        st.text_area(
            "YouTube èªªæ˜æ¬„ï¼ˆå·²åŒ…å«æœ¬æ¬¡æ–‡æœ¬èˆ‡å›ºå®šèªªæ˜ï¼Œå¯ç›´æ¥è¤‡è£½ï¼‰ï¼š",
            value=combined_for_description,
            height=260,
        )

    if start_clicked:
        if not cleaned_text.strip():
            st.error("è«‹å…ˆè¼¸å…¥è¦è½‰æˆèªéŸ³çš„ Markdown æ–‡æœ¬ã€‚")
            return

        # æ ¹æ“š Markdown ç¬¬ä¸€å€‹æ¨™é¡Œ + æ™‚é–“æˆ³ç”¢ç”Ÿæª”ååŸºåº•
        heading_match = re.search(r"^\s*#+\s+(.*)$", raw_markdown, flags=re.MULTILINE)
        heading = heading_match.group(1).strip() if heading_match else "output"

        # ä½¿ç”¨è€…å¦‚æœ‰è‡ªè¨‚å‰ç¶´ï¼Œå„ªå…ˆä½¿ç”¨
        base_label = base_name.strip() if base_name.strip() else heading

        # ç°¡å–®æ¸…ç†æª”åï¼šç§»é™¤ä¸é©åˆçš„ç¬¦è™Ÿ
        def sanitize_filename(s: str) -> str:
            s = s.strip()
            # åªä¿ç•™å¸¸è¦‹å®‰å…¨å­—å…ƒï¼Œå…¶é¤˜ç”¨åº•ç·šä»£æ›¿
            return "".join(
                (c if c.isalnum() or c in " _-ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹é›¶ã€‡å£¹è²³åƒè‚†ä¼é™¸æŸ’æŒç–æ‹¾ç™¾åƒè¬å„„" else "_")
                for c in s
            ).replace(" ", "_")

        safe_label = sanitize_filename(base_label) or "output"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        final_base = f"{safe_label}_{timestamp}"

        # è¼¸å‡ºè³‡æ–™å¤¾
        output_dir = "azure_outputs"
        os.makedirs(output_dir, exist_ok=True)

        audio_filename = os.path.join(output_dir, f"{final_base}.mp3")
        video_filename = os.path.join(output_dir, f"{final_base}.mp4")
        subtitle_txt_filename = os.path.join(output_dir, f"{final_base}.txt")

        # å°‡æ¸…æ´—å¾Œã€æ¯å¥ä¸€è¡Œçš„æ–‡æœ¬è¼¸å‡ºæˆ .txtï¼Œæ–¹ä¾¿é¤µçµ¦ YouTube åšå­—å¹•
        if display_text:
            try:
                with open(subtitle_txt_filename, "w", encoding="utf-8") as f:
                    f.write(display_text)
            except Exception as e:
                st.warning(f"è¼¸å‡ºå­—å¹•ç”¨æ–‡æœ¬æª”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

        # æº–å‚™ Azure TTS
        speech_config = get_speech_config()
        if voice:
            speech_config.speech_synthesis_voice_name = voice

        # æº–å‚™è¦é€é€² TTS çš„åˆ†æ®µæ–‡æœ¬
        def build_segments_auto(all_sentences, per_segment: int):
            if not all_sentences:
                return []
            if per_segment <= 0:
                return [" ".join(all_sentences).strip()]
            segments = []
            total = len(all_sentences)
            start = 0
            while start < total:
                end = min(start + per_segment, total)
                segments.append(" ".join(all_sentences[start:end]).strip())
                start = end
            return [s for s in segments if s]

        # ä¾é•·æ–‡æœ¬æ¨¡å¼æ±ºå®šåˆ†æ®µï¼›å¦å‰‡æ•´ç¯‡ä¸€æ¬¡é€å‡º
        tts_segments = []
        if segmentation_mode == "auto" and sentences:
            tts_segments = build_segments_auto(sentences, sentences_per_segment)
        else:
            # é€€è€Œæ±‚å…¶æ¬¡ï¼Œä»¥ cleaned_text ç•¶ä½œå–®ä¸€æ®µ
            tts_segments = [cleaned_text]

        if not tts_segments:
            st.error("æ²’æœ‰å¯ç”¨ä¾†èªéŸ³åˆæˆçš„æ–‡æœ¬åˆ†æ®µã€‚")
            return

        st.info(f"æœ¬æ¬¡å°‡åˆ†æˆ {len(tts_segments)} æ®µé€²è¡ŒèªéŸ³åˆæˆã€‚")

        # é€æ®µåˆæˆï¼Œè¼¸å‡ºå¤šå€‹è‡¨æ™‚éŸ³æª”ï¼Œå†ä¹‹å¾Œåˆä½µ
        part_files = []
        progress_bar = st.progress(0)

        for idx, segment in enumerate(tts_segments, start=1):
            part_path = os.path.join(output_dir, f"{final_base}_part_{idx:03d}.mp3")
            audio_config_part = speechsdk.audio.AudioConfig(filename=part_path)
            synthesizer_part = speechsdk.SpeechSynthesizer(
                speech_config=speech_config,
                audio_config=audio_config_part,
            )

            with st.spinner(f"Azure æ­£åœ¨åˆæˆç¬¬ {idx}/{len(tts_segments)} æ®µâ€¦"):
                result = synthesizer_part.speak_text_async(segment).get()

            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                part_files.append(part_path)
                progress_bar.progress(idx / len(tts_segments))
            elif result.reason == speechsdk.ResultReason.Canceled:
                cancellation = result.cancellation_details
                st.error(
                    f"ç¬¬ {idx} æ®µåˆæˆè¢«å–æ¶ˆï¼š{cancellation.reason} - {cancellation.error_details}"
                )
                return
            else:
                st.error(f"ç¬¬ {idx} æ®µåˆæˆçµæœæœªçŸ¥ï¼š{result.reason}")
                return

        progress_bar.progress(1.0)

        # æ‰€æœ‰åˆ†æ®µçš†æˆåŠŸåˆæˆå¾Œï¼Œä½¿ç”¨ ffmpeg concat æ¨¡å¼åˆä½µç‚ºä¸€å€‹å®Œæ•´ MP3
        concat_list_path = os.path.join(output_dir, f"{final_base}_concat_list.txt")
        try:
            with open(concat_list_path, "w", encoding="utf-8") as f:
                for part in part_files:
                    # ffmpeg concat æª”æ¡ˆåˆ—è¡¨æ ¼å¼ï¼šfile 'path'
                    f.write(f"file '{os.path.abspath(part)}'\n")

            with st.spinner("æ­£åœ¨åˆä½µå„æ®µéŸ³æª”ç‚ºå®Œæ•´ MP3â€¦"):
                subprocess.run(
                    [
                        "ffmpeg",
                        "-y",
                        "-f",
                        "concat",
                        "-safe",
                        "0",
                        "-i",
                        concat_list_path,
                        "-c",
                        "copy",
                        audio_filename,
                    ],
                    stdin=subprocess.DEVNULL,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                    check=True,
                )
            # åˆä½µæˆåŠŸå¾Œï¼Œæ¸…ç†ä¸­é–“åˆ‡ç‰‡æª”èˆ‡æ¸…å–®æª”ï¼Œåªä¿ç•™å®Œæ•´ MP3
            for part in part_files:
                try:
                    os.remove(part)
                except Exception:
                    pass
            try:
                os.remove(concat_list_path)
            except Exception:
                pass
        except subprocess.CalledProcessError as e:
            st.error(f"åˆä½µåˆ†æ®µéŸ³æª”æ™‚ ffmpeg ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return
        except Exception as e:
            st.error(f"åˆä½µåˆ†æ®µéŸ³æª”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return

        st.success(
            f"èªéŸ³åˆæˆå®Œæˆï¼Œå·²è¼¸å‡ºéŸ³æª”ï¼š{audio_filename}\n"
            f"å­—å¹•ç”¨ç´”æ–‡å­—æª”ï¼š{subtitle_txt_filename}"
        )

        # æ’­æ”¾ MP3ï¼ˆåªé¡¯ç¤ºä¸€å€‹æ’­æ”¾å™¨ï¼›è‹¥å‹¾é¸è‡ªå‹•æ’­æ”¾å‰‡ç”¨ HTML5 autoplayï¼Œå¦å‰‡ç”¨ st.audioï¼‰
        try:
            with open(audio_filename, "rb") as f:
                audio_bytes = f.read()

            if auto_play:
                b64_audio = base64.b64encode(audio_bytes).decode("utf-8")
                components.html(
                    f"""
                    <audio controls autoplay>
                        <source src="data:audio/mpeg;base64,{b64_audio}" type="audio/mpeg">
                        Your browser does not support the audio element.
                    </audio>
                    """,
                    height=80,
                )
            else:
                st.audio(audio_bytes, format="audio/mp3")
        except Exception as e:
            st.warning(f"éŸ³æª”å·²ç”¢ç”Ÿï¼Œä½†è®€å–æ’­æ”¾æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

        # è‹¥é¸æ“‡ç”¢ç”Ÿå½±ç‰‡ï¼Œå‘¼å« ffmpeg åšé»‘åº•å½±ç‰‡ï¼ˆä½¿ç”¨åˆä½µå¾Œçš„å®Œæ•´éŸ³æª”ï¼‰
        if mode == "ç”¢ç”Ÿé»‘åº• MP4 å½±ç‰‡":
            video_progress = st.progress(0)
            with st.spinner("æ­£åœ¨ç”¨ ffmpeg ç”Ÿæˆé»‘åº•å½±ç‰‡â€¦"):
                try:
                    # å°‡éŸ³è¨Šå»¶é²æŒ‡å®šç§’æ•¸ï¼Œä½¿å½±ç‰‡é–‹é ­å…ˆæœ‰å¹¾ç§’ç„¡è²ç•«é¢
                    delay_ms = int(locals().get("video_lead_seconds", 5) * 1000)
                    subprocess.run(
                        [
                            "ffmpeg",
                            "-y",
                            "-f",
                            "lavfi",
                            "-i",
                            "color=c=black:s=1920x1080:r=30",
                            "-i",
                            audio_filename,
                            "-af",
                            f"adelay={delay_ms}|{delay_ms}",
                            "-shortest",
                            video_filename,
                        ],
                        stdin=subprocess.DEVNULL,
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        check=True,
                    )
                    video_progress.progress(100)
                    st.success(f"å½±ç‰‡ç”Ÿæˆå®Œæˆï¼š{video_filename}")
                    st.video(video_filename)
                except subprocess.CalledProcessError as e:
                    st.error(f"ç”Ÿæˆå½±ç‰‡æ™‚ ffmpeg ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


if __name__ == "__main__":
    main()
